# Memory - 2026-02-07

## Estratégia de Otimização e Infraestrutura
- **Objetivo Principal:** Reduzir custos de API em 90%+ seguindo a lógica do vídeo de Matt Ganzac (Token Optimization).
- **Hardware do Carlos:** RTX 3090 (24GB VRAM) + 128GB RAM.
- **Arquitetura Tiered (Zeus):**
  - **Tier 1 (Principal/Local):** Qwen 2.5 32B / DeepSeek-R1 32B (Raciocínio forte na GPU).
  - **Tier 2 (Fallback):** Qwen 2.5 14B (Em instalação).
  - **Tier 3 (Sistema/Heartbeats):** Llama 3 8B / Mistral 7B (Em instalação). O objetivo é mover os heartbeats para o Ollama local para poupar tokens de API.
  - **Cloud:** Kimi 2.5 (Moonshot) e Gemini 3 Flash para tarefas multimodais e raciocínio de última instância.

## Decisões Técnicas
- **Backup:** Criado `openclaw_restauro_baseline_20260207.json` antes de alterações na config.
- **Provider:** Moonshot AI (Kimi) adicionado com sucesso usando a chave `kimiAPI`.
- **Tuning:** Configurar `OLLAMA_NUM_PARALLEL=1` e limitar contexto a 8k nos modelos locais para estabilidade na 3090.

## Tarefas em Curso
- Instalação de `qwen2.5:14b` e `llama3:8b` via Ollama.
- Planeamento da migração de heartbeats para o Ollama local.
